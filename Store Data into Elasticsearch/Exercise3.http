# ** EXAM OBJECTIVE: INDEXING DATA **
# GOAL: Create an alias, reindex indices, and create data pipelines
# REQUIRED SETUP:
#    (i)   a running Elasticsearch cluster with at least one node
#          and a Kibana instance,
#    (ii)  the cluster has no index with name `hamlet`,
#    (iii) the cluster has no template that applies to indices
#          starting by `hamlet`
DELETE hamlet-1/
DELETE hamlet-2/

DELETE  _template/hamlet_template

# Create the indices `hamlet-1` and `hamlet-2`, each with two
#    primary shards and no replicas

PUT /hamlet-1
{
   "settings" : {
       "index" : {
           "number_of_shards" : 2,
           "number_of_replicas" : 0
       }
   }
}

PUT /hamlet-2
{
   "settings" : {
       "index" : {
           "number_of_shards" : 2,
           "number_of_replicas" : 0
       }
   }
}


GET hamlet-2/_search

GET hamlet-1/_search

# Create the alias `hamlet` that maps both `hamlet-1` and `hamlet-2`
POST /_aliases
{
   "actions" : [
       { "add" : { "indices" : ["hamlet-1", "hamlet-2"], "alias" : "hamlet" } }
   ]
}

# Verify that the documents grouped by `hamlet` are 8
GET hamlet/_count

# By default, if your alias includes more than one index, you cannot index documents using the alias name.
# Configure `hamlet-1` to be the write index of the `hamlet` alias
POST /_aliases
{
   "actions" : [
       {
           "add" : {
                "index" : "hamlet-1",
                "alias" : "hamlet",
                "is_write_index" : true
           }
       }, {
           "add" : {
                "index" : "hamlet-2",
                "alias" : "hamlet",
                "is_write_index" : false
           }
       }
   ]
}

# Add a document to `hamlet`, so that the document (i) has id "8",
#    (ii) has "_doc" type, (iii) has a field `text_entry` with value
#    "With turbulent and dangerous lunacy?", (iv) has a field
#    `line_number` with value "3.1.4", (v) has a field `speaker`
#    with value "KING CLAUDIUS"
PUT /hamlet/_doc/8
{
   "text_entry" : "With turbulent and dangerous lunacy?",
   "line_number" : "3.1.4",
   "speaker" : "KING CLAUDIUS"
}

GET hamlet/_count

GET hamlet-2/_search

# Create a script named `control_reindex_batch` and save it into the
#    cluster state. The script checks whether a document has the
#    field `reindexBatch`, and (i) in the affirmative case, it
#    increments the field value by a script parameter named
#    `increment`, (ii) otherwise, the script adds the field to the
#    document setting its value to "1"
POST _scripts/control_reindex_batch
{
 "script": {
   "lang": "painless",
   "source": """
         if (ctx._source.containsKey("reindexBatch")) {
            ctx._source.reindexBatch += params.increment;
         } else {
            ctx._source.reindexBatch = 1;
         }
   """,
   "params": {
     "increment": "1"
   }
    
 }
}

POST hamlet/_update_by_query
{
  "script": {
   "id": "control_reindex_batch"
 }
}


#For a more efficient reindexing, a best practice is to temporarily configure the destination index to have no replicas as well as to disable “index.refresh_interval”

# Create the index `hamlet-new` with 2 primary shards and no
#    replicas
# Reindex `hamlet` into `hamlet-new`, while satisfying the following
#    criteria: (i) apply the `control_reindex_batch` script with the
#    `increment` parameter set to "1", (ii) reindex using two
#    parallel slices

#The most basic form of _reindex just copies documents from one index to another. This will copy documents from the twitter index into the new_twitter index:

POST _reindex
{
 "source": {
   "index": "hamlet",
    "slice": {
     "id": 0,
     "max": 2
   }
 },
 "dest": {
   "index": "hamlet-new"
 },
 "script": {
     "id" : "control_reindex_batch",
     "params": {
       "increment": 1
     }
 }
}


POST _reindex
{
 "source": {
   "index": "hamlet",
    "slice": {
     "id": 1,
     "max": 2
   }
 },
 "dest": {
   "index": "hamlet-new"
 },
 "script": {
     "id" : "control_reindex_batch",
     "params": {
       "increment": 1
     }
 }
}

GET hamlet/_search

# In one request, add `hamlet-new` to the alias `hamlet` and delete
#    the `hamlet` and `hamlet-2` indices
POST /_aliases
{
   "actions" : [
       {
           "add" : {
                "index" : "hamlet-new",
                "alias" : "hamlet"
           }
       }, {
           "remove" : {
                "indices" : ["hamlet-1", "hamlet-2" ],
                "alias" : "hamlet"
           }
       }
   ]
}

# Create a pipeline named `split_act_scene_line`. The pipeline
#    splits the value of `line_number` using the dots as a
#    separator, and stores the split values into three
#    new fields named `number_act`, `number_scene`, and
#    `number_line`, respectively

PUT _ingest/pipeline/split_act_scene_line
{
     "description" : "split act scene line",
     "processors": [
       {
         "split": {
           "field": "line_number",
            "tag": "splitMessageProcessor",
           "separator": "\\.+",
           "target_field": "splitedMessage",
           "ignore_missing" : true
         },
         "script": {
           "source": """
             ctx.number_act = ctx.splitedMessage.0;
             ctx.number_scene = ctx.splitedMessage.1;
             ctx.number_line = ctx.splitedMessage.2;
           """
         },
         "remove" : {
           "field": "splitedMessage"
         }
       }
     ]
}


# Update all documents in `hamlet-new` by using the
#    `split_act_scene_line` pipeline
POST hamlet-new/_update_by_query?pipeline=split_act_scene_line


GET hamlet-new/_search
